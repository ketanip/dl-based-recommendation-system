{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abb7ed00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.2.6-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.19.0-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp312-cp312-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ketan\\desktop\\super-store-sales\\venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Using cached absl_py-2.3.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\ketan\\desktop\\super-store-sales\\venv\\lib\\site-packages (from tensorflow) (25.0)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Using cached protobuf-5.29.5-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting requests<3,>=2.21.0 (from tensorflow)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting setuptools (from tensorflow)\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\ketan\\desktop\\super-store-sales\\venv\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Using cached termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting typing-extensions>=3.6.6 (from tensorflow)\n",
      "  Using cached typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Using cached wrapt-1.17.2-cp312-cp312-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Using cached grpcio-1.71.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
      "  Using cached tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Using cached keras-3.10.0-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.1.3-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Using cached h5py-3.13.0-cp312-cp312-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Using cached ml_dtypes-0.5.1-cp312-cp312-win_amd64.whl.metadata (22 kB)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.15.3-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
      "  Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting rich (from keras>=3.5.0->tensorflow)\n",
      "  Using cached rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Using cached namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Using cached optree-0.16.0-cp312-cp312-win_amd64.whl.metadata (31 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Using cached charset_normalizer-3.4.2-cp312-cp312-win_amd64.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Using cached urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Using cached certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Using cached markdown-3.8-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow)\n",
      "  Using cached MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.5.0->tensorflow)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\ketan\\desktop\\super-store-sales\\venv\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading pandas-2.2.3-cp312-cp312-win_amd64.whl (11.5 MB)\n",
      "   ---------------------------------------- 0.0/11.5 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/11.5 MB 5.6 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 2.1/11.5 MB 5.3 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.7/11.5 MB 6.2 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 5.2/11.5 MB 6.5 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 6.8/11.5 MB 6.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.7/11.5 MB 7.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.0/11.5 MB 7.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.5/11.5 MB 7.7 MB/s eta 0:00:00\n",
      "Using cached tensorflow-2.19.0-cp312-cp312-win_amd64.whl (376.0 MB)\n",
      "Using cached numpy-2.1.3-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "Downloading scikit_learn-1.6.1-cp312-cp312-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 2.1/11.1 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 4.7/11.1 MB 11.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.3/11.1 MB 11.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.0/11.1 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.1/11.1 MB 11.6 MB/s eta 0:00:00\n",
      "Using cached absl_py-2.3.0-py3-none-any.whl (135 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Using cached grpcio-1.71.0-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "Using cached h5py-3.13.0-cp312-cp312-win_amd64.whl (3.0 MB)\n",
      "Using cached joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Using cached keras-3.10.0-py3-none-any.whl (1.4 MB)\n",
      "Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "Using cached ml_dtypes-0.5.1-cp312-cp312-win_amd64.whl (210 kB)\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Using cached protobuf-5.29.5-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading scipy-1.15.3-cp312-cp312-win_amd64.whl (41.0 MB)\n",
      "   ---------------------------------------- 0.0/41.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.8/41.0 MB 10.0 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 4.2/41.0 MB 10.1 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 6.0/41.0 MB 10.0 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 7.9/41.0 MB 9.5 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 9.7/41.0 MB 9.0 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 11.0/41.0 MB 8.6 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 12.1/41.0 MB 8.1 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 12.6/41.0 MB 7.7 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 14.4/41.0 MB 7.5 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 14.9/41.0 MB 7.3 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 14.9/41.0 MB 7.3 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 14.9/41.0 MB 7.3 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 16.5/41.0 MB 6.0 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 18.1/41.0 MB 6.1 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 19.4/41.0 MB 6.1 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 21.0/41.0 MB 6.2 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 22.5/41.0 MB 6.3 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 24.4/41.0 MB 6.4 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 26.5/41.0 MB 6.6 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 28.0/41.0 MB 6.7 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 29.6/41.0 MB 6.7 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 31.5/41.0 MB 6.8 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 33.3/41.0 MB 6.9 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 35.1/41.0 MB 7.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 37.2/41.0 MB 7.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 39.1/41.0 MB 7.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 39.8/41.0 MB 7.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/41.0 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 41.0/41.0 MB 6.8 MB/s eta 0:00:00\n",
      "Using cached tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "Using cached termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Using cached typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Using cached wrapt-1.17.2-cp312-cp312-win_amd64.whl (38 kB)\n",
      "Using cached certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
      "Using cached charset_normalizer-3.4.2-cp312-cp312-win_amd64.whl (105 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached markdown-3.8-py3-none-any.whl (106 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Using cached namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Using cached optree-0.16.0-cp312-cp312-win_amd64.whl (315 kB)\n",
      "Using cached rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl (15 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: pytz, namex, libclang, flatbuffers, wrapt, wheel, urllib3, tzdata, typing-extensions, threadpoolctl, termcolor, tensorboard-data-server, setuptools, protobuf, opt-einsum, numpy, mdurl, MarkupSafe, markdown, joblib, idna, grpcio, google-pasta, gast, charset-normalizer, certifi, absl-py, werkzeug, scipy, requests, pandas, optree, ml-dtypes, markdown-it-py, h5py, astunparse, tensorboard, scikit-learn, rich, keras, tensorflow\n",
      "Successfully installed MarkupSafe-3.0.2 absl-py-2.3.0 astunparse-1.6.3 certifi-2025.4.26 charset-normalizer-3.4.2 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.71.0 h5py-3.13.0 idna-3.10 joblib-1.5.1 keras-3.10.0 libclang-18.1.1 markdown-3.8 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.5.1 namex-0.1.0 numpy-2.1.3 opt-einsum-3.4.0 optree-0.16.0 pandas-2.2.3 protobuf-5.29.5 pytz-2025.2 requests-2.32.3 rich-14.0.0 scikit-learn-1.6.1 scipy-1.15.3 setuptools-80.9.0 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 termcolor-3.1.0 threadpoolctl-3.6.0 typing-extensions-4.13.2 tzdata-2025.2 urllib3-2.4.0 werkzeug-3.1.3 wheel-0.45.1 wrapt-1.17.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas numpy tensorflow scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1de80d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d70449b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Row ID</th>\n",
       "      <th>Order ID</th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Ship Date</th>\n",
       "      <th>Ship Mode</th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Customer Name</th>\n",
       "      <th>Segment</th>\n",
       "      <th>Country</th>\n",
       "      <th>City</th>\n",
       "      <th>...</th>\n",
       "      <th>Postal Code</th>\n",
       "      <th>Region</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Category</th>\n",
       "      <th>Sub-Category</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>CA-2013-152156</td>\n",
       "      <td>2013-11-09</td>\n",
       "      <td>2013-11-12</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>CG-12520</td>\n",
       "      <td>Claire Gute</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>...</td>\n",
       "      <td>42420</td>\n",
       "      <td>South</td>\n",
       "      <td>FUR-BO-10001798</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Bookcases</td>\n",
       "      <td>Bush Somerset Collection Bookcase</td>\n",
       "      <td>261.9600</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>41.9136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>CA-2013-152156</td>\n",
       "      <td>2013-11-09</td>\n",
       "      <td>2013-11-12</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>CG-12520</td>\n",
       "      <td>Claire Gute</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>...</td>\n",
       "      <td>42420</td>\n",
       "      <td>South</td>\n",
       "      <td>FUR-CH-10000454</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Chairs</td>\n",
       "      <td>Hon Deluxe Fabric Upholstered Stacking Chairs,...</td>\n",
       "      <td>731.9400</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>219.5820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>CA-2013-138688</td>\n",
       "      <td>2013-06-13</td>\n",
       "      <td>2013-06-17</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>DV-13045</td>\n",
       "      <td>Darrin Van Huff</td>\n",
       "      <td>Corporate</td>\n",
       "      <td>United States</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>...</td>\n",
       "      <td>90036</td>\n",
       "      <td>West</td>\n",
       "      <td>OFF-LA-10000240</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Labels</td>\n",
       "      <td>Self-Adhesive Address Labels for Typewriters b...</td>\n",
       "      <td>14.6200</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.8714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>US-2012-108966</td>\n",
       "      <td>2012-10-11</td>\n",
       "      <td>2012-10-18</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>SO-20335</td>\n",
       "      <td>Sean O'Donnell</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Fort Lauderdale</td>\n",
       "      <td>...</td>\n",
       "      <td>33311</td>\n",
       "      <td>South</td>\n",
       "      <td>FUR-TA-10000577</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Tables</td>\n",
       "      <td>Bretford CR4500 Series Slim Rectangular Table</td>\n",
       "      <td>957.5775</td>\n",
       "      <td>5</td>\n",
       "      <td>0.45</td>\n",
       "      <td>-383.0310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>US-2012-108966</td>\n",
       "      <td>2012-10-11</td>\n",
       "      <td>2012-10-18</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>SO-20335</td>\n",
       "      <td>Sean O'Donnell</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Fort Lauderdale</td>\n",
       "      <td>...</td>\n",
       "      <td>33311</td>\n",
       "      <td>South</td>\n",
       "      <td>OFF-ST-10000760</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Storage</td>\n",
       "      <td>Eldon Fold 'N Roll Cart System</td>\n",
       "      <td>22.3680</td>\n",
       "      <td>2</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2.5164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Row ID        Order ID Order Date  Ship Date       Ship Mode Customer ID  \\\n",
       "0       1  CA-2013-152156 2013-11-09 2013-11-12    Second Class    CG-12520   \n",
       "1       2  CA-2013-152156 2013-11-09 2013-11-12    Second Class    CG-12520   \n",
       "2       3  CA-2013-138688 2013-06-13 2013-06-17    Second Class    DV-13045   \n",
       "3       4  US-2012-108966 2012-10-11 2012-10-18  Standard Class    SO-20335   \n",
       "4       5  US-2012-108966 2012-10-11 2012-10-18  Standard Class    SO-20335   \n",
       "\n",
       "     Customer Name    Segment        Country             City  ...  \\\n",
       "0      Claire Gute   Consumer  United States        Henderson  ...   \n",
       "1      Claire Gute   Consumer  United States        Henderson  ...   \n",
       "2  Darrin Van Huff  Corporate  United States      Los Angeles  ...   \n",
       "3   Sean O'Donnell   Consumer  United States  Fort Lauderdale  ...   \n",
       "4   Sean O'Donnell   Consumer  United States  Fort Lauderdale  ...   \n",
       "\n",
       "  Postal Code  Region       Product ID         Category Sub-Category  \\\n",
       "0       42420   South  FUR-BO-10001798        Furniture    Bookcases   \n",
       "1       42420   South  FUR-CH-10000454        Furniture       Chairs   \n",
       "2       90036    West  OFF-LA-10000240  Office Supplies       Labels   \n",
       "3       33311   South  FUR-TA-10000577        Furniture       Tables   \n",
       "4       33311   South  OFF-ST-10000760  Office Supplies      Storage   \n",
       "\n",
       "                                        Product Name     Sales  Quantity  \\\n",
       "0                  Bush Somerset Collection Bookcase  261.9600         2   \n",
       "1  Hon Deluxe Fabric Upholstered Stacking Chairs,...  731.9400         3   \n",
       "2  Self-Adhesive Address Labels for Typewriters b...   14.6200         2   \n",
       "3      Bretford CR4500 Series Slim Rectangular Table  957.5775         5   \n",
       "4                     Eldon Fold 'N Roll Cart System   22.3680         2   \n",
       "\n",
       "   Discount    Profit  \n",
       "0      0.00   41.9136  \n",
       "1      0.00  219.5820  \n",
       "2      0.00    6.8714  \n",
       "3      0.45 -383.0310  \n",
       "4      0.20    2.5164  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"Superstore.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a5e425b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Row ID', 'Order ID', 'Order Date', 'Ship Date', 'Ship Mode',\n",
       "       'Customer ID', 'Customer Name', 'Segment', 'Country', 'City', 'State',\n",
       "       'Postal Code', 'Region', 'Product ID', 'Category', 'Sub-Category',\n",
       "       'Product Name', 'Sales', 'Quantity', 'Discount', 'Profit'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20eb19ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Customer ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FUR-BO-10001798</td>\n",
       "      <td>CG-12520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FUR-CH-10000454</td>\n",
       "      <td>CG-12520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OFF-LA-10000240</td>\n",
       "      <td>DV-13045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FUR-TA-10000577</td>\n",
       "      <td>SO-20335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OFF-ST-10000760</td>\n",
       "      <td>SO-20335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Product ID Customer ID\n",
       "0  FUR-BO-10001798    CG-12520\n",
       "1  FUR-CH-10000454    CG-12520\n",
       "2  OFF-LA-10000240    DV-13045\n",
       "3  FUR-TA-10000577    SO-20335\n",
       "4  OFF-ST-10000760    SO-20335"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions_cols =  [\"Product ID\", \"Customer ID\"]\n",
    "interactions = df[interactions_cols]\n",
    "interactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b68e8d21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Product Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FUR-BO-10001798</td>\n",
       "      <td>Bush Somerset Collection Bookcase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FUR-CH-10000454</td>\n",
       "      <td>Hon Deluxe Fabric Upholstered Stacking Chairs,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OFF-LA-10000240</td>\n",
       "      <td>Self-Adhesive Address Labels for Typewriters b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FUR-TA-10000577</td>\n",
       "      <td>Bretford CR4500 Series Slim Rectangular Table</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OFF-ST-10000760</td>\n",
       "      <td>Eldon Fold 'N Roll Cart System</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Product ID                                       Product Name\n",
       "0  FUR-BO-10001798                  Bush Somerset Collection Bookcase\n",
       "1  FUR-CH-10000454  Hon Deluxe Fabric Upholstered Stacking Chairs,...\n",
       "2  OFF-LA-10000240  Self-Adhesive Address Labels for Typewriters b...\n",
       "3  FUR-TA-10000577      Bretford CR4500 Series Slim Rectangular Table\n",
       "4  OFF-ST-10000760                     Eldon Fold 'N Roll Cart System"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_cols = [\"Product ID\", \"Product Name\"]\n",
    "products = df[products_cols]\n",
    "products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "caa22fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# useless_cols = [\"Row ID\", \"Order ID\", \"Customer Name\", \"Ship Date\", \"Ship Mode\", \"Region\", \"Product Name\", \"Profit\", \"Quantity\", \"Sales\"]\n",
    "# df = df.drop(columns=useless_cols)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31c47258",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [col.strip().replace(\" \", \"_\") for col in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35f4704b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "user_enc = LabelEncoder()\n",
    "item_enc = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec448c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['user_id'] = user_enc.fit_transform(df['Customer_ID'])\n",
    "df['item_id'] = item_enc.fit_transform(df['Product_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69405610",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = df['user_id'].nunique()\n",
    "num_items = df['item_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ff8c23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_features_df = df[['item_id', 'Category', 'Sub-Category', 'Discount']].drop_duplicates('item_id')\n",
    "item_features_df = pd.get_dummies(item_features_df.set_index('item_id'), columns=['Category', 'Sub-Category'])\n",
    "item_features = item_features_df.sort_index().values.astype('float32')  # shape: (num_items, feature_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "747d6de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = df[['user_id', 'item_id']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c8c991c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_set = interactions.groupby('user_id')['item_id'].apply(set).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4dcb3b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_info = df[['item_id', 'Product_ID', 'Product_Name']].drop_duplicates('item_id')\n",
    "product_id_to_name = dict(zip(product_info['item_id'], product_info['Product_Name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48100f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(interactions, num_items, num_negatives=3):\n",
    "    user_ids, item_ids, labels = [], [], []\n",
    "\n",
    "    for user, item in interactions.to_numpy():\n",
    "        user_ids.append(user)\n",
    "        item_ids.append(item)\n",
    "        labels.append(1)\n",
    "\n",
    "        for _ in range(num_negatives):\n",
    "            neg = np.random.randint(0, num_items)\n",
    "            while neg in user_item_set[user]:\n",
    "                neg = np.random.randint(0, num_items)\n",
    "            user_ids.append(user)\n",
    "            item_ids.append(neg)\n",
    "            labels.append(0)\n",
    "    \n",
    "    return np.array(user_ids), np.array(item_ids), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76f60982",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids, item_ids, labels = sample_data(interactions, num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2f2eb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, Model\n",
    "import tensorflow as tf\n",
    "\n",
    "embedding_dim = 64\n",
    "item_content_tensor = tf.convert_to_tensor(item_features)  # constant\n",
    "\n",
    "class HybridRecommender(Model):\n",
    "    def __init__(self, num_users, item_feature_dim, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.user_embedding = layers.Embedding(num_users, embedding_dim)\n",
    "        self.item_content_encoder = tf.keras.Sequential([\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dense(embedding_dim)\n",
    "        ])\n",
    "        self.item_features = tf.constant(item_content_tensor)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        user_input, item_input = inputs\n",
    "        user_emb = self.user_embedding(user_input)\n",
    "        item_feat = tf.gather(self.item_features, item_input)\n",
    "        item_emb = self.item_content_encoder(item_feat)\n",
    "        dot_product = tf.reduce_sum(user_emb * item_emb, axis=1)\n",
    "        return dot_product\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0eecc1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0098 - loss: 0.6575 - val_accuracy: 0.0000e+00 - val_loss: 0.5745\n",
      "Epoch 2/5\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0051 - loss: 0.5637 - val_accuracy: 0.0000e+00 - val_loss: 0.5723\n",
      "Epoch 3/5\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0082 - loss: 0.5574 - val_accuracy: 0.0000e+00 - val_loss: 0.5743\n",
      "Epoch 4/5\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.5494 - val_accuracy: 0.0000e+00 - val_loss: 0.5825\n",
      "Epoch 5/5\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0031 - loss: 0.5334 - val_accuracy: 0.0000e+00 - val_loss: 0.5937\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x22f67c62e70>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split for validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    np.stack([user_ids, item_ids], axis=1), labels, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "# Prepare tf.data datasets\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(((X_train[:,0], X_train[:,1]), y_train)).batch(256).shuffle(1024)\n",
    "val_ds = tf.data.Dataset.from_tensor_slices(((X_val[:,0], X_val[:,1]), y_val)).batch(256)\n",
    "\n",
    "# Instantiate and compile model\n",
    "model = HybridRecommender(num_users, item_features.shape[1], embedding_dim)\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "\n",
    "# Train\n",
    "model.fit(train_ds, validation_data=val_ds, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f13a026",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('hybrid_recommender_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ca3bb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_product_status_df(user_str, top_k=5):\n",
    "    try:\n",
    "        user_id = user_enc.transform([user_str])[0]\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"User '{user_str}' not found in the dataset.\")\n",
    "    \n",
    "    # --- Seen products ---\n",
    "    seen_item_ids = list(user_item_set.get(user_id, []))\n",
    "    seen_product_ids = item_enc.inverse_transform(seen_item_ids)\n",
    "    seen_names = [product_id_to_name.get(iid, 'Unknown') for iid in seen_item_ids]\n",
    "\n",
    "    seen_df = pd.DataFrame({\n",
    "        'Product ID': seen_product_ids,\n",
    "        'Product Name': seen_names,\n",
    "        'Status': ['purchased previously'] * len(seen_item_ids)\n",
    "    })\n",
    "\n",
    "    # --- Predicted products (excluding seen) ---\n",
    "    all_items = np.arange(num_items)\n",
    "    candidate_items = np.setdiff1d(all_items, seen_item_ids)\n",
    "    user_tensor = np.full_like(candidate_items, fill_value=user_id)\n",
    "\n",
    "    scores = model.predict([user_tensor, candidate_items], batch_size=512)\n",
    "    top_indices = np.argsort(scores)[-top_k:][::-1]\n",
    "    top_item_ids = candidate_items[top_indices]\n",
    "    predicted_product_ids = item_enc.inverse_transform(top_item_ids)\n",
    "    predicted_names = [product_id_to_name.get(iid, 'Unknown') for iid in top_item_ids]\n",
    "\n",
    "    predicted_df = pd.DataFrame({\n",
    "        'Product ID': predicted_product_ids,\n",
    "        'Product Name': predicted_names,\n",
    "        'Status': ['predicted'] * top_k\n",
    "    })\n",
    "\n",
    "    # --- Combine both ---\n",
    "    return pd.concat([seen_df, predicted_df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7c4691e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FUR-BO-10001798</td>\n",
       "      <td>Bush Somerset Collection Bookcase</td>\n",
       "      <td>purchased previously</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OFF-PA-10003001</td>\n",
       "      <td>Xerox 1986</td>\n",
       "      <td>purchased previously</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FUR-CH-10000454</td>\n",
       "      <td>Hon Deluxe Fabric Upholstered Stacking Chairs,...</td>\n",
       "      <td>purchased previously</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FUR-FU-10004952</td>\n",
       "      <td>C-Line Cubicle Keepers Polyproplyene Holder w/...</td>\n",
       "      <td>purchased previously</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OFF-ST-10000615</td>\n",
       "      <td>SimpliFile Personal File, Black Granite, 15w x...</td>\n",
       "      <td>purchased previously</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FUR-FU-10004712</td>\n",
       "      <td>Westinghouse Mesh Shade Clip-On Gooseneck Lamp...</td>\n",
       "      <td>predicted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FUR-FU-10004748</td>\n",
       "      <td>Howard Miller 16\" Diameter Gallery Wall Clock</td>\n",
       "      <td>predicted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FUR-FU-10004845</td>\n",
       "      <td>Deflect-o EconoMat Nonstudded, No Bevel Mat</td>\n",
       "      <td>predicted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FUR-FU-10004864</td>\n",
       "      <td>Howard Miller 14-1/2\" Diameter Chrome Round Wa...</td>\n",
       "      <td>predicted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FUR-FU-10004960</td>\n",
       "      <td>Seth Thomas 12\" Clock w/ Goldtone Case</td>\n",
       "      <td>predicted</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Product ID                                       Product Name  \\\n",
       "0  FUR-BO-10001798                  Bush Somerset Collection Bookcase   \n",
       "1  OFF-PA-10003001                                         Xerox 1986   \n",
       "2  FUR-CH-10000454  Hon Deluxe Fabric Upholstered Stacking Chairs,...   \n",
       "3  FUR-FU-10004952  C-Line Cubicle Keepers Polyproplyene Holder w/...   \n",
       "4  OFF-ST-10000615  SimpliFile Personal File, Black Granite, 15w x...   \n",
       "5  FUR-FU-10004712  Westinghouse Mesh Shade Clip-On Gooseneck Lamp...   \n",
       "6  FUR-FU-10004748      Howard Miller 16\" Diameter Gallery Wall Clock   \n",
       "7  FUR-FU-10004845        Deflect-o EconoMat Nonstudded, No Bevel Mat   \n",
       "8  FUR-FU-10004864  Howard Miller 14-1/2\" Diameter Chrome Round Wa...   \n",
       "9  FUR-FU-10004960             Seth Thomas 12\" Clock w/ Goldtone Case   \n",
       "\n",
       "                 Status  \n",
       "0  purchased previously  \n",
       "1  purchased previously  \n",
       "2  purchased previously  \n",
       "3  purchased previously  \n",
       "4  purchased previously  \n",
       "5             predicted  \n",
       "6             predicted  \n",
       "7             predicted  \n",
       "8             predicted  \n",
       "9             predicted  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_product_df = get_user_product_status_df('CG-12520', top_k=5)\n",
    "user_product_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b77db0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
